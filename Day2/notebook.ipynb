{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SGD.__init__() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# SGD\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sgd \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SGD.__init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "\n",
    "sgd = optim.SGD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters which needs to be optimized and the learning rate (optional) should be passed into the `SGD` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks\n",
    "\n",
    "```\n",
    "nn.Linear\n",
    "nn.Module\n",
    "nn.Sequential\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.Linear` -> Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 40.2087, -24.8985], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "layer1 = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "input1 = torch.tensor([5., 8, 78])\n",
    "\n",
    "output1 = layer1(input1)\n",
    "\n",
    "output1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch uses **Kaiming Uniform** (also known as **He initialization**) for weight initialization in the `nn.Linear` layers.\n",
    "- The above code doesn't invlove any activation functions, so activation functions are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2273, -0.2373,  0.5208],\n",
       "        [-0.0505, -0.3087, -0.2887]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2273, -0.2373,  0.5208],\n",
       "        [-0.0505, -0.3087, -0.2887]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(layer1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3498, 0.3395], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everytime, we run this code, the `output`, `weights` and `biases` all changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also pass in our custom weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 625., 1112.], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = torch.tensor([[1., 5., 7], [9, 8, 12]])\n",
    "new_bias = torch.tensor([34., 67])\n",
    "\n",
    "layer1.weight.data = new_weights\n",
    "layer1.bias.data = new_bias\n",
    "\n",
    "layer1(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we assign weights from our side, eventhough we didn't explicitly set `requires_grad=True`, it would automatically be set when it is passes into the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also send in inputs as batches and get the output as batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 103.,  197.],\n",
       "        [ 137.,  271.],\n",
       "        [ 692., 1214.],\n",
       "        [ 323.,  872.]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input = torch.tensor([[2., 5, 6], [4, 3, 12], [3, 5, 90], [45, 32, 12]])\n",
    "\n",
    "batch_output = layer1(batch_input)\n",
    "\n",
    "batch_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to create a model, we need to create a class for that model, that should inherit from the class `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__init__` function, we need to define the attributes which we will be using in our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if `cuda` is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegressionModel()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# reshaping into a single column to feed them as a batch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m pred\n",
      "File \u001b[0;32m~/New Folder/Pytorch-Workshop/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/New Folder/Pytorch-Workshop/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mLinearRegressionModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/New Folder/Pytorch-Workshop/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/New Folder/Pytorch-Workshop/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/New Folder/Pytorch-Workshop/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "model = LinearRegressionModel().to(device)\n",
    "\n",
    "X = torch.linspace(0, 10, 15).reshape(-1, 1) # reshaping into a single column to feed them as a batch\n",
    "\n",
    "pred = model(X)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using the device to be `cuda` for the model, then the corresponding inputs also should be passed to `cuda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7296],\n",
       "        [ 0.5647],\n",
       "        [ 0.3999],\n",
       "        [ 0.2351],\n",
       "        [ 0.0702],\n",
       "        [-0.0946],\n",
       "        [-0.2595],\n",
       "        [-0.4243],\n",
       "        [-0.5892],\n",
       "        [-0.7540],\n",
       "        [-0.9189],\n",
       "        [-1.0837],\n",
       "        [-1.2485],\n",
       "        [-1.4134],\n",
       "        [-1.5782]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionModel().to(device)\n",
    "\n",
    "X = torch.linspace(0, 10, 15).reshape(-1, 1) # reshaping into a single column to feed them as a batch\n",
    "\n",
    "pred = model(X.to(device))\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE : There is no training happening here, the outputs are based on randomly initialized weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the weights and biases of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2308]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.7296], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us create a little more complicated architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 5) # We can pass in the atributes as positional arguments\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (layer1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SimpleModel().to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0523,  0.2966,  0.2654, -0.8964, -0.1073,  0.1461, -0.5090, -0.8233,\n",
       "         -0.0809, -0.7292]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 10, device='cuda') # This function samples random numbers from normal gaussian distribution\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4151]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing `weights` and `biases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2644, -0.0841, -0.1459,  0.2434,  0.1147, -0.1956, -0.1965, -0.2665,\n",
      "          0.2801,  0.0398],\n",
      "        [ 0.3009, -0.2574,  0.2046, -0.1350, -0.1687, -0.0546,  0.0036, -0.2978,\n",
      "          0.1113, -0.0969],\n",
      "        [ 0.1085, -0.0845, -0.0679,  0.0925,  0.2768,  0.1475, -0.1495,  0.1683,\n",
      "         -0.1441, -0.0730],\n",
      "        [-0.1590,  0.2901,  0.1041, -0.2682, -0.0775,  0.1011,  0.2388, -0.1736,\n",
      "         -0.2450,  0.0178],\n",
      "        [-0.2974, -0.0525, -0.0943,  0.1964, -0.1471,  0.1625, -0.1029,  0.2435,\n",
      "          0.2896,  0.2747]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1117,  0.0657, -0.2407,  0.2795, -0.3070], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0062, -0.1048, -0.0991,  0.2970,  0.1173]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2661], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net.layer1.weight)\n",
    "print(net.layer1.bias)\n",
    "print(net.layer2.weight)\n",
    "print(net.layer2.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access all the parameters of the architecture in a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f25285c4d60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a generator object, we can iterate this to print its components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2644, -0.0841, -0.1459,  0.2434,  0.1147, -0.1956, -0.1965, -0.2665,\n",
      "          0.2801,  0.0398],\n",
      "        [ 0.3009, -0.2574,  0.2046, -0.1350, -0.1687, -0.0546,  0.0036, -0.2978,\n",
      "          0.1113, -0.0969],\n",
      "        [ 0.1085, -0.0845, -0.0679,  0.0925,  0.2768,  0.1475, -0.1495,  0.1683,\n",
      "         -0.1441, -0.0730],\n",
      "        [-0.1590,  0.2901,  0.1041, -0.2682, -0.0775,  0.1011,  0.2388, -0.1736,\n",
      "         -0.2450,  0.0178],\n",
      "        [-0.2974, -0.0525, -0.0943,  0.1964, -0.1471,  0.1625, -0.1029,  0.2435,\n",
      "          0.2896,  0.2747]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1117,  0.0657, -0.2407,  0.2795, -0.3070], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0062, -0.1048, -0.0991,  0.2970,  0.1173]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2661], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for params in net.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is same as what we maually printed above, so the parameters function stores the parameters sequentially with respect to forward pass\n",
    "\n",
    "Let us cross check the shape of each of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for params in net.parameters():\n",
    "    print(params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could create same kind of neural net architecture using this `Sequential` module too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no creation of class involved simple creation and calling similar to `TensorFlow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2947]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 10, device='cuda')\n",
    "output = model(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we haven't explicitly named the layers, so can't call these individual layers by name, but we can access it using its indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2549, -0.0182,  0.2610, -0.1604,  0.2725,  0.0594, -0.0114, -0.0512,\n",
      "          0.2818,  0.0081],\n",
      "        [-0.1267,  0.2653, -0.1773,  0.2910, -0.0359,  0.0135,  0.1166, -0.3002,\n",
      "         -0.2791,  0.1083],\n",
      "        [-0.2520,  0.2365, -0.1996,  0.2720, -0.2562, -0.2832,  0.2073, -0.0305,\n",
      "         -0.1315, -0.1527],\n",
      "        [-0.1308,  0.2541, -0.0111, -0.0506,  0.0829,  0.1642, -0.0962,  0.0690,\n",
      "          0.0524, -0.1591],\n",
      "        [-0.2239, -0.1286, -0.1554, -0.1998, -0.2868, -0.2321, -0.1363, -0.2854,\n",
      "         -0.1585, -0.1241]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2813, -0.3044, -0.1827,  0.0463, -0.0414], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0906,  0.2802,  0.1067, -0.3017, -0.1425]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2947], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0].weight)\n",
    "print(model[0].bias)\n",
    "print(model[2].weight)\n",
    "print(model[2].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the flow of the network is not sequential or is little much complex, it is always better to prefer class method of initializing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 1.1393691301345825\n",
      "Epoch : 100 Loss : 1.0666722059249878\n",
      "Epoch : 200 Loss : 1.0147347450256348\n",
      "Epoch : 300 Loss : 0.9591621160507202\n",
      "Epoch : 400 Loss : 0.9025018811225891\n",
      "Epoch : 500 Loss : 0.8571661114692688\n",
      "Epoch : 600 Loss : 0.8176199197769165\n",
      "Epoch : 700 Loss : 0.7862420678138733\n",
      "Epoch : 800 Loss : 0.7647578120231628\n",
      "Epoch : 900 Loss : 0.7462576031684875\n"
     ]
    }
   ],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NewModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(5, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# Creating random inputs and targets\n",
    "inputs = torch.randn(100, 10, device='cuda')\n",
    "targets = torch.randn(100, 1, device='cuda')\n",
    "\n",
    "# Initializing the model\n",
    "net = NewModel().to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # deleting the gradients accumulated in the optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # Loss computation\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch :\", epoch, \"Loss :\", loss.item())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `loss.backward()` will do the backprop and store all the gradients in the `variable.grad`\n",
    "- `optimizer.step()` will take these gradients and update the weights and biases in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'NewModel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General steps to use an Optimizer\n",
    "\n",
    "1. Zero the gradients (`optimizer.zero_grad()`)\n",
    "2. Compute the output (**Forward Pass**)\n",
    "3. Compute the loss\n",
    "4. Perform Backpropagation (`loss.backward()`)\n",
    "5. Update the parameters (`optimizer.step()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Pratical Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.63372971],\n",
       "       [18.28983954],\n",
       "       [24.43092073],\n",
       "       [ 3.8195586 ],\n",
       "       [12.76322617],\n",
       "       [12.96709416],\n",
       "       [ 6.96006959],\n",
       "       [20.40287098],\n",
       "       [11.94817018],\n",
       "       [33.2537514 ],\n",
       "       [17.35023922],\n",
       "       [12.25429802],\n",
       "       [10.73072924],\n",
       "       [27.38448129],\n",
       "       [ 4.54690019],\n",
       "       [ 9.64828572],\n",
       "       [ 4.68295233],\n",
       "       [26.05124116],\n",
       "       [23.25290643],\n",
       "       [ 7.86587409],\n",
       "       [ 8.61071717],\n",
       "       [ 6.54809278],\n",
       "       [ 6.07171251],\n",
       "       [29.66525869],\n",
       "       [20.5077538 ],\n",
       "       [23.66472099],\n",
       "       [26.43899279],\n",
       "       [29.53215063],\n",
       "       [10.98338677],\n",
       "       [ 4.84543538],\n",
       "       [ 7.63473347],\n",
       "       [26.07908336],\n",
       "       [ 6.82088007],\n",
       "       [23.57632765],\n",
       "       [21.59728661],\n",
       "       [ 6.62908682],\n",
       "       [13.69267172],\n",
       "       [27.83709377],\n",
       "       [26.42383826],\n",
       "       [ 5.09547195],\n",
       "       [ 8.65526774],\n",
       "       [26.02229582],\n",
       "       [ 2.85716174],\n",
       "       [13.06541412],\n",
       "       [12.40309881],\n",
       "       [24.95104412],\n",
       "       [ 7.83325397],\n",
       "       [27.95950061],\n",
       "       [30.50497088],\n",
       "       [30.40724434],\n",
       "       [ 8.73593633],\n",
       "       [17.0745862 ],\n",
       "       [ 9.140104  ],\n",
       "       [ 6.42116901],\n",
       "       [27.41729366],\n",
       "       [ 5.19911157],\n",
       "       [11.65699705],\n",
       "       [ 8.88640534],\n",
       "       [21.5972212 ],\n",
       "       [16.13905107],\n",
       "       [20.05032091],\n",
       "       [21.86602471],\n",
       "       [19.29641535],\n",
       "       [23.36840869],\n",
       "       [ 9.80517605],\n",
       "       [29.48607937],\n",
       "       [25.70414461],\n",
       "       [10.51391384],\n",
       "       [26.13383611],\n",
       "       [18.74339994],\n",
       "       [11.01898019],\n",
       "       [19.98550453],\n",
       "       [19.5159358 ],\n",
       "       [20.35818729],\n",
       "       [ 7.34552701],\n",
       "       [19.03495321],\n",
       "       [26.88865661],\n",
       "       [ 7.12163149],\n",
       "       [19.48960122],\n",
       "       [16.05643275],\n",
       "       [15.49420177],\n",
       "       [14.25123288],\n",
       "       [14.4986287 ],\n",
       "       [25.69148306],\n",
       "       [15.47402728],\n",
       "       [12.48768201],\n",
       "       [ 9.20479106],\n",
       "       [21.72721199],\n",
       "       [31.5105369 ],\n",
       "       [ 7.1926525 ],\n",
       "       [ 6.56821727],\n",
       "       [22.00393273],\n",
       "       [ 6.97355727],\n",
       "       [ 7.70587392],\n",
       "       [ 3.94683497],\n",
       "       [ 9.19307375],\n",
       "       [ 7.21849279],\n",
       "       [12.58520018],\n",
       "       [22.59203744],\n",
       "       [ 3.09808413]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(100, 1)*10\n",
    "true_w = 3\n",
    "true_b = 2\n",
    "\n",
    "y = true_w*X + true_b + np.random.randn(100, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32, device='cuda')\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32, device='cuda')\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32, device='cuda')\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(LinearRegression, self).__init__()\n",
    "    self.linear = nn.Linear(1, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n",
    "model = LinearRegression().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8373137712478638\n",
      "-0.9680311679840088\n"
     ]
    }
   ],
   "source": [
    "print(model.linear.weight.item())\n",
    "print(model.linear.bias.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 99 Loss : 1.576372742652893\n",
      "Epoch : 199 Loss : 1.267047643661499\n",
      "Epoch : 299 Loss : 1.1508183479309082\n",
      "Epoch : 399 Loss : 1.107145071029663\n",
      "Epoch : 499 Loss : 1.090734601020813\n",
      "Epoch : 599 Loss : 1.0845683813095093\n",
      "Epoch : 699 Loss : 1.0822514295578003\n",
      "Epoch : 799 Loss : 1.081380844116211\n",
      "Epoch : 899 Loss : 1.0810539722442627\n",
      "Epoch : 999 Loss : 1.0809309482574463\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "  optimizer.zero_grad()\n",
    "  outputs = model(X_train)\n",
    "  loss = criterion(outputs, y_train)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if (epoch+1) % 100 == 0:\n",
    "    print(\"Epoch :\", epoch, \"Loss :\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7884, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  pred = model(X_test)\n",
    "  test_loss = criterion(pred, y_test)\n",
    "\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.no_grad()` is used to save memory, we should use it only for inference because `requires_grad=False` will be set by default for all the processes running inside the block of `torch.no_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.023601770401001\n",
      "1.7040432691574097\n"
     ]
    }
   ],
   "source": [
    "print(model.linear.weight.item())\n",
    "print(model.linear.bias.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is very close to the true weight and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "dataset = fetch_california_housing()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32, device='cuda')\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32, device='cuda')\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32, device='cuda')\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePriceNet(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(HousePriceNet, self).__init__()\n",
    "    self.layer1 = nn.Linear(8, 5)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.layer2 = nn.Linear(5, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.layer2(x)\n",
    "    return x\n",
    "  \n",
    "hpn = HousePriceNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 18969.583984375\n",
      "Epoch : 100 Loss : 863394004992.0\n",
      "Epoch : 200 Loss : 15185329152.0\n",
      "Epoch : 300 Loss : 267078944.0\n",
      "Epoch : 400 Loss : 4697374.5\n",
      "Epoch : 500 Loss : 82618.484375\n",
      "Epoch : 600 Loss : 1454.4029541015625\n",
      "Epoch : 700 Loss : 26.89315414428711\n",
      "Epoch : 800 Loss : 1.7861838340759277\n",
      "Epoch : 900 Loss : 1.3446040153503418\n"
     ]
    }
   ],
   "source": [
    "mse = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(hpn.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "  optimizer.zero_grad()\n",
    "  output = hpn(X_train)\n",
    "  loss = mse(output.reshape(16512), y_train.reshape(16512))\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if (epoch % 100) == 0:\n",
    "    print(\"Epoch :\", epoch, \"Loss :\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3111, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ic40844/New Folder/Pytorch-Workshop/venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([4128])) that is different to the input size (torch.Size([4128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  pred = hpn(X_test)\n",
    "  test_loss = criterion(pred, y_test)\n",
    "\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have constructed, trained and evaluated an ANN using Pytorch on a real-world dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
