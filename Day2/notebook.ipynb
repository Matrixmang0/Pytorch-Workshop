{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "\n",
    "sgd = optim.SGD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks\n",
    "\n",
    "```\n",
    "nn.Linear\n",
    "nn.Module\n",
    "nn.Sequential\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.Linear` -> Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4326,  8.3574], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "layer1 = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "input1 = torch.tensor([5., 8, 78])\n",
    "\n",
    "output1 = layer1(input1)\n",
    "\n",
    "output1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch uses **Kaiming Uniform** (also known as **He initialization**) for weight initialization in the `nn.Linear` layers.\n",
    "- The above code doesn't invlove any activation functions, so activation functions are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2250, -0.4629,  0.0513],\n",
       "        [ 0.1548, -0.5298,  0.1502]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2250, -0.4629,  0.0513],\n",
       "        [ 0.1548, -0.5298,  0.1502]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(layer1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3948, 0.1081], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everytime, we run this code, the `output`, `weights` and `biases` all changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also pass in our custom weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 625., 1112.], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = torch.tensor([[1., 5., 7], [9, 8, 12]])\n",
    "new_bias = torch.tensor([34., 67])\n",
    "\n",
    "layer1.weight.data = new_weights\n",
    "layer1.bias.data = new_bias\n",
    "\n",
    "layer1(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we assign weights from our side, eventhough we didn't explicitly set `requires_grad=True`, it would automatically be set when it is passes into the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also send in inputs as batches and get the output as batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 103.,  197.],\n",
       "        [ 137.,  271.],\n",
       "        [ 692., 1214.],\n",
       "        [ 323.,  872.]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input = torch.tensor([[2., 5, 6], [4, 3, 12], [3, 5, 90], [45, 32, 12]])\n",
    "\n",
    "batch_output = layer1(batch_input)\n",
    "\n",
    "batch_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to create a model, we need to create a class for that model, that should inherit from the class `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__init__` function, we need to define the attributes which we will be using in our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2982],\n",
       "        [0.7075],\n",
       "        [1.1167],\n",
       "        [1.5259],\n",
       "        [1.9352],\n",
       "        [2.3444],\n",
       "        [2.7536],\n",
       "        [3.1628],\n",
       "        [3.5721],\n",
       "        [3.9813],\n",
       "        [4.3905],\n",
       "        [4.7998],\n",
       "        [5.2090],\n",
       "        [5.6182],\n",
       "        [6.0275]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionModel()\n",
    "\n",
    "X = torch.linspace(0, 10, 15).reshape(-1, 1) # reshaping into a single column to feed them as a batch\n",
    "\n",
    "pred = model(X)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE : There is no training happening here, the outputs are based on randomly initialized weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the weights and biases of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.5729]], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2982], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us create a little more complicated architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 5) # We can pass in the atributes as positional arguments\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (layer1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SimpleModel()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2133, -0.6530, -0.4642,  0.4322, -0.3934, -0.3582,  0.1788, -0.5381,\n",
       "         -2.9398,  0.3000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 10) # This function samples random numbers from normal gaussian distribution\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1228]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing `weights` and `biases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0409, -0.2381, -0.1773, -0.0067,  0.2568, -0.1257, -0.1149,  0.0955,\n",
      "         -0.1825, -0.1549],\n",
      "        [ 0.1729,  0.1043, -0.1728, -0.1504,  0.2014,  0.2415,  0.1694,  0.1043,\n",
      "          0.0391,  0.2934],\n",
      "        [-0.0633,  0.2307,  0.1636, -0.0048, -0.1066, -0.0436,  0.1575, -0.2524,\n",
      "          0.2767,  0.1501],\n",
      "        [-0.1252, -0.2697,  0.1006,  0.0077,  0.2431,  0.2081, -0.2368,  0.1665,\n",
      "          0.0122,  0.1779],\n",
      "        [-0.1188,  0.2325,  0.0076,  0.0448, -0.2391,  0.3124, -0.0504,  0.2967,\n",
      "         -0.0150, -0.0129]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2813, -0.2151, -0.2072,  0.1852,  0.0900], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1299, -0.2960,  0.4257, -0.2743, -0.0747]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0531], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net.layer1.weight)\n",
    "print(net.layer1.bias)\n",
    "print(net.layer2.weight)\n",
    "print(net.layer2.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access all the parameters of the architecture in a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f44538433e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a generator object, we can iterate this to print its components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0409, -0.2381, -0.1773, -0.0067,  0.2568, -0.1257, -0.1149,  0.0955,\n",
      "         -0.1825, -0.1549],\n",
      "        [ 0.1729,  0.1043, -0.1728, -0.1504,  0.2014,  0.2415,  0.1694,  0.1043,\n",
      "          0.0391,  0.2934],\n",
      "        [-0.0633,  0.2307,  0.1636, -0.0048, -0.1066, -0.0436,  0.1575, -0.2524,\n",
      "          0.2767,  0.1501],\n",
      "        [-0.1252, -0.2697,  0.1006,  0.0077,  0.2431,  0.2081, -0.2368,  0.1665,\n",
      "          0.0122,  0.1779],\n",
      "        [-0.1188,  0.2325,  0.0076,  0.0448, -0.2391,  0.3124, -0.0504,  0.2967,\n",
      "         -0.0150, -0.0129]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2813, -0.2151, -0.2072,  0.1852,  0.0900], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1299, -0.2960,  0.4257, -0.2743, -0.0747]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0531], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for params in net.parameters():\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is same as what we maually printed above, so the parameters function stores the parameters sequentially with respect to forward pass\n",
    "\n",
    "Let us cross check the shape of each of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for params in net.parameters():\n",
    "    print(params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could create same kind of neural net architecture using this `Sequential` module too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no creation of class involved simple creation and calling similar to `TensorFlow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0470]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 10)\n",
    "output = model(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we haven'y explicitly named the layers, so can't call these individual layers by name, but we can access it using its indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0788,  0.1867, -0.2808, -0.0681,  0.2860,  0.1389, -0.1130,  0.2014,\n",
      "         -0.1127, -0.0666],\n",
      "        [ 0.1796, -0.0856,  0.2900, -0.2269, -0.2764, -0.0511, -0.0214, -0.0933,\n",
      "         -0.1643,  0.1824],\n",
      "        [-0.1410, -0.3136, -0.3014,  0.1758,  0.0503, -0.1323, -0.1685,  0.0956,\n",
      "         -0.1987,  0.1828],\n",
      "        [-0.3150, -0.1256,  0.2114, -0.2085,  0.2123,  0.0087, -0.0036,  0.0950,\n",
      "         -0.0398,  0.0453],\n",
      "        [-0.0447,  0.0477,  0.1345, -0.1228, -0.3094,  0.1953, -0.1709,  0.1493,\n",
      "          0.1032, -0.0887]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1045,  0.0719, -0.1628,  0.1493,  0.2043], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1367, -0.3759,  0.3436,  0.3287,  0.0239]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0386], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0].weight)\n",
    "print(model[0].bias)\n",
    "print(model[2].weight)\n",
    "print(model[2].bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
